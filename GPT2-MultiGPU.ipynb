{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f2d32d-a2a5-4d07-82a8-a75f9d59a5c2",
   "metadata": {},
   "source": [
    "## Translating NanoGPT (GPT2) to TensorFlow\n",
    "\n",
    "#### Based on https://github.com/karpathy/nanoGPT/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd63294-aad8-43f0-af26-fd269065c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "import numpy as np\n",
    "from  dataclasses import dataclass\n",
    "from tensorflow.experimental import numpy as tnp\n",
    "import tensorflow_probability as tfp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d165d-446a-4967-af31-7d2533743d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27095ef9-33f5-49b9-934b-c72fa4e7c4d2",
   "metadata": {},
   "source": [
    "## Distribute Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cb0f5-7757-4149-93f1-6afb9b040507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e066ce-3b7f-4b67-9baf-0447689759ca",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1815235f-5c52-47f2-b907-d76302440ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayerNorm(tf.keras.layers.Layer):\n",
    "    def __init__(self, bias=True, eps=1e-6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "        self.bias = bias\n",
    "       \n",
    "    def build(self, input_shape):  \n",
    "        self.weight = self.add_weight(name='weight',\n",
    "                                      shape=input_shape[-1:], # [-1:] gives last elem but keeps dims\n",
    "                                      initializer=tf.keras.initializers.Ones(),\n",
    "                                      trainable=True)\n",
    "\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                      shape=input_shape[-1:], # [-1:] gives last elem but keeps dims\n",
    "                                      initializer=tf.keras.initializers.Zeros(),\n",
    "                                      trainable=True) if self.bias else None\n",
    "\n",
    "        super(MyLayerNorm, self).build(input_shape)\n",
    "    @tf.function(jit_compile=True)\n",
    "    def call(self, x):\n",
    "        # Can also use tf.nn.moments(inputs, axes=-1, keepdims=True), \n",
    "        # but then additionally one needs to take the sqrt to get \\sigma\n",
    "        mean = tf.keras.backend.mean(x, axis=-1, keepdims=True)\n",
    "        std = tf.keras.backend.std(x, axis=-1, keepdims=True)\n",
    "        \n",
    "        return self.weight * (x - mean) / (std + self.eps) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7d1d04-d22c-4bc7-94d3-520589437843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTConfig():\n",
    "    def __init__(self, \n",
    "                 block_size:int=8, \n",
    "                 vocab_size:int=39,\n",
    "                 n_layer:int=2,\n",
    "                 n_head:int=2,\n",
    "                 n_embd:int=10,\n",
    "                 dropout:float=0.0,\n",
    "                 bias:bool=False,\n",
    "                 seed:int=1337):\n",
    "\n",
    "        self.block_size=block_size\n",
    "        self.vocab_size=vocab_size\n",
    "        self.n_layer=n_layer\n",
    "        self.n_head=n_head\n",
    "        self.n_embd=n_embd\n",
    "        self.dropout=dropout\n",
    "        self.bias=bias\n",
    "        self.seed=seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62748a28-fe5e-447a-9ee0-364f628721b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0, \"Embedding dimension must divide number of heads\"\n",
    "        # key, query, value computed at once and splitted later\n",
    "        self.initializer_proj = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02 / tf.math.sqrt(2. * config.n_layer), seed=None)\n",
    "        self.c_attn = tf.keras.layers.Dense(#config.n_embd,\n",
    "                                            3 * config.n_embd,\n",
    "                                            activation=None,\n",
    "                                            use_bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = tf.keras.layers.Dense(#config.n_embd,\n",
    "                                            config.n_embd,\n",
    "                                            activation=None,\n",
    "                                            kernel_initializer=self.initializer_proj,\n",
    "                                            use_bias=config.bias)\n",
    "        self.dropout = config.dropout\n",
    "        self.attn_dropout = tf.keras.layers.Dropout(self.dropout)\n",
    "        self.resid_dropout = tf.keras.layers.Dropout(self.dropout)\n",
    "\n",
    "        self.mask = tf.experimental.numpy.tril(\n",
    "            tf.ones([config.block_size, config.block_size]))[tf.newaxis, tf.newaxis, :, :]\n",
    "    \n",
    "    @tf.function(jit_compile=True)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, C = x.size() # batch, sequence and channel, which is the embedding dim\n",
    "\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, axis=2)\n",
    "        k = tf.transpose(tf.reshape(k, [B, T, self.n_head, C // self.n_head]),\n",
    "                         perm=[0, 2, 1, 3])\n",
    "        q = tf.transpose(tf.reshape(q, [B, T, self.n_head, C // self.n_head]),\n",
    "                         perm=[0, 2, 1, 3])\n",
    "        v = tf.transpose(tf.reshape(v, [B, T, self.n_head, C // self.n_head]),\n",
    "                         perm=[0, 2, 1, 3])\n",
    "\n",
    "        att = (q @ tf.transpose(k, perm=[0, 1, 3, 2])) * (1.0 / tf.math.sqrt(k.shape[-1]))\n",
    "\n",
    "        mask = tf.experimental.numpy.tril(tf.ones([T, T]))[tf.newaxis, tf.newaxis, :, :]\n",
    "        att = tf.where(mask != 0, att, tf.constant(-np.inf))\n",
    "        att = tf.nn.softmax(att, axis = 3)\n",
    "        att = self.attn_dropout(att)\n",
    "        y = att @ v\n",
    "\n",
    "        y = tf.reshape(tf.transpose(y, perm=[0, 2, 1, 3]), [B, T, C])\n",
    "\n",
    "        return self.resid_dropout(self.c_proj(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f03ff7b-782a-44ce-90d6-740bea8696d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.layers.Layer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.initializer_proj = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02 / tf.math.sqrt(2. * config.n_layer), seed=None)\n",
    "        # Streching and shrinking in channel/embedding dimension,\n",
    "        # like for large resnets\n",
    "        self.c_fc = tf.keras.layers.Dense(4 * config.n_embd, activation=None, use_bias=config.bias)\n",
    "        self.c_proj = tf.keras.layers.Dense(config.n_embd, activation=None, kernel_initializer=self.initializer_proj, use_bias=config.bias)\n",
    "        self.gelu = tf.keras.activations.gelu\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "    \n",
    "    @tf.function(jit_compile=True)\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return self.dropout(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b9f2e7-a6ca-42f1-a4f1-9fd4c70a5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(tf.keras.layers.Layer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = MyLayerNorm(bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = MyLayerNorm(bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "    \n",
    "    @tf.function(jit_compile=True)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        return x + self.mlp(self.ln_2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c27098-de9a-4d27-81dd-03252d470f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(tf.keras.models.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "\n",
    "        self.initializer_dense = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02, seed=self.config.seed)\n",
    "        self.initializer_embed = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02, seed=self.config.seed)\n",
    "        self.initializer_bias = tf.keras.initializers.Zeros()\n",
    "        \n",
    "        self.wte = tf.keras.layers.Embedding(self.config.vocab_size, \n",
    "                                             self.config.n_embd, \n",
    "                                             embeddings_initializer=self.initializer_embed, \n",
    "                                             name='wte')\n",
    "        \n",
    "        self.wpe = tf.keras.layers.Embedding(self.config.block_size, \n",
    "                                             self.config.n_embd, \n",
    "                                             embeddings_initializer=self.initializer_embed, \n",
    "                                             name='wpe')\n",
    "        \n",
    "        self.drop = tf.keras.layers.Dropout(self.config.dropout, name='drop')\n",
    "        \n",
    "        self.h = [Block(self.config) for _ in range(self.config.n_layer)]\n",
    "        \n",
    "        self.ln_f = MyLayerNorm(bias=self.config.bias, name='ln_f')\n",
    "        \n",
    "        # Crucial for mixed precision: final model output should be of dtype='float32'\n",
    "        self.lm_head = tf.keras.layers.Dense(self.config.vocab_size, use_bias=self.config.bias, dtype='float32')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.wte.build(input_shape=[self.config.vocab_size])\n",
    "        self.lm_head.build(input_shape=[self.config.n_embd])\n",
    "        self.wte.trainable_weights[0].assign(tf.transpose(self.lm_head.trainable_weights[0]))\n",
    "    \n",
    "    @tf.function(jit_compile=True)\n",
    "    def call(self, idx):\n",
    "        b, t = idx.shape\n",
    "        #assert t <= self.config.block_size, f'sequence too long for the defined context of {self.config.block_size}'\n",
    "        pos = tf.range(0, t, dtype=tf.int64)\n",
    "\n",
    "        tok_emb = self.wte(idx)\n",
    "        pos_emb = self.wpe(pos)\n",
    "        x = self.drop(tok_emb + pos_emb)\n",
    "        for block in self.h:\n",
    "            x = block(x)\n",
    "        x = self.ln_f(x)\n",
    "        return self.lm_head(x)\n",
    "\n",
    "    def crop_block_size(self, block_size):\n",
    "        assert block_size < self.config.block_size\n",
    "        self.config.block_size = block_size\n",
    "        self.wpe.weights[0] = tf.Variable(self.wpe.weights[0][:block_size], trainable=True)\n",
    "        for block in self.h:\n",
    "            #if hasattr(block.attn, 'bias'):\n",
    "            if len(block.attn.weights) == 2:\n",
    "                block.attn.bias = block.attn.bias[:, :, :block_size, :block_size]\n",
    "                  \n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        n_params = self.count_params()\n",
    "        if non_embedding:\n",
    "            n_params -= self.wpe.count_params()\n",
    "        return n_params\n",
    "        \n",
    "    def estimate_mfu(self, fwdbwd_per_iter, dt):\n",
    "        N = self.get_num_params()\n",
    "        L, H, Q, T = self.config.n_layer, self.config.n_head, self.config.n_embd / self.config.n_head, self.config.block_size\n",
    "        flops_per_token = 6 * N + 12 * L * H * Q * T\n",
    "        flops_per_fwdbwd = flops_per_token * T\n",
    "        flops_per_iter = flops_per_fwdbwd * fwdbwd_per_iter\n",
    "        flops_achieved = flops_per_iter * (1.0/dt)\n",
    "        flops_promised = 312e12 # A100 at bfloat16\n",
    "        mfu = flops_achieved / flops_promised\n",
    "        return mfu\n",
    "        \n",
    "    @tf.function(jit_compile=True)\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        for i in range(max_new_tokens):\n",
    "            idx_cond = idx if idx.shape[1] <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            logits = self(idx_cond, training=False)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, _ = tf.math.top_k(logits, min(top_k, logits.shape[-1]))\n",
    "                # Returned top_k values are sorted, so [-1] is the smallest of top_k\n",
    "                # and we cut all below that value\n",
    "                logits[logits < v[:, -1]] = -float('Inf')\n",
    "            probs = tf.keras.activations.softmax(logits, axis=-1)\n",
    "            idx_dist = tfp.distributions.Multinomial(total_count=1, probs=probs)\n",
    "            idx_next = idx_dist.sample(1)\n",
    "            idx_next = tf.reshape(tf.math.argmax(idx_next, axis=-1), shape=(-1, 1))\n",
    "            idx = tf.concat([idx, idx_next], axis=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b90f6-c158-4bce-bfa5-aeea6c0bae30",
   "metadata": {},
   "source": [
    "## Auxilliary routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39dbff70-dc5b-4945-ae35-0d5ca5e44d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self,\n",
    "                 learning_rate: float = 6e-4,\n",
    "                 warmup_iters: int = 10,                \n",
    "                 min_lr: float = 6e-5,\n",
    "                 lr_decay_iters: int= 100):\n",
    "    \n",
    "        self.learning_rate = learning_rate\n",
    "        self.warmup_iters = warmup_iters\n",
    "        self.min_lr = min_lr\n",
    "        self.lr_decay_iters = lr_decay_iters\n",
    "\n",
    "    def warmup(self, step):\n",
    "        def res():            \n",
    "            return self.learning_rate * float(step) / self.warmup_iters\n",
    "        return res\n",
    "        \n",
    "    def late(self):\n",
    "        return self.min_lr\n",
    "    \n",
    "    def middle(self, step):\n",
    "        def res():\n",
    "            decay_ratio = (float(step) - self.warmup_iters) / (self.lr_decay_iters - self.warmup_iters)\n",
    "            #assert 0 <= decay_ratio <= 1\n",
    "            coeff = 0.5 * (1.0 + tf.math.cos(tnp.pi * decay_ratio))        \n",
    "            return self.min_lr + coeff * (self.learning_rate - self.min_lr)\n",
    "        return res\n",
    "        \n",
    "    @tf.function(jit_compile=True)\n",
    "    def __call__(self, step):\n",
    "        lr = tf.case([(tf.less(step, self.warmup_iters), self.warmup(step)),\n",
    "                   (tf.greater(step, self.lr_decay_iters), self.late)],\n",
    "                   default=self.middle(step), exclusive=True)\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445c587-127f-4847-a376-83137d4872eb",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9783bf-ffd8-47a7-a96d-7e565b2fd426",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespear_url = \"https://homl.info/shakespeare\"\n",
    "filepath = tf.keras.utils.get_file('shakespear.txt', shakespear_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b924d61-10ce-4a53-9bcf-988ac292bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath, 'r', encoding='utf-8') as f:\n",
    "    shakespear_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc58f79-1e89-4670-968d-b5ac2ddeaf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(shakespear_txt[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "895d2e3f-a3b9-4206-8a42-9c8ef6878241",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(split='character',\n",
    "                                                  standardize='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69510b33-0bc0-4949-8354-a3e46e6ce141",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer.adapt([shakespear_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cb9ef03-8cb6-460e-86e1-0f4ef25bddc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', ' ', 'e', 't', 'o', 'a', 'i', 'h', 's']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c1790fb-ae48-4d91-8271-52dd1e9728e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = text_vec_layer([shakespear_txt])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a193190e-994c-4102-9641-9b6094057233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48b4bc16-834b-4dcb-bf3a-9dcf99a75cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing code 0 and 1 reserved for padding and unknown characters \n",
    "# (codes start at 2 before that removal so now 0 and 1 will be some chars)\n",
    "encoded -= 2\n",
    "\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2\n",
    "dataset_size = len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f67da86c-ac61-4c4e-9a1d-df7ae567eed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3ef9654-7a8f-46a7-bd8a-2c05f4c7eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42db9390-638c-4bc8-89a9-2fb3a8bf608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=512):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length+1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53836358-b36f-4325-ad67-69dfa6bd38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 32\n",
    "tf.random.set_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b70c83e-72b1-4449-87b5-c805e996e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = to_dataset(encoded[:1_060_000], length=length, shuffle=True, seed=1337)\n",
    "valid_set = to_dataset(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c389baff-d9d6-4592-8faa-1429d90f4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sample in train_set.rebatch(1).take(1):\n",
    "#    print(sample[0])\n",
    "#    print(sample[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e12c47-3a94-418b-ab0b-88dac5e26688",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97a7a825-e4ca-4684-9fef-d50ebc0a500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#buffer_size = 1024\n",
    "batch_per_replica = 512\n",
    "global_batch_size = batch_per_replica * strategy.num_replicas_in_sync\n",
    "\n",
    "n_layer = 8\n",
    "n_head = 8\n",
    "n_embd = 32\n",
    "block_size = length\n",
    "bias = True\n",
    "vocab_size = n_tokens\n",
    "dropout = 0.1\n",
    "\n",
    "iter_num = 0\n",
    "best_val_loss = 1e9\n",
    "max_iters = 250\n",
    "\n",
    "weight_decay = 1e-1\n",
    "\n",
    "warmup_iters = 50\n",
    "learning_rate = 6e-4\n",
    "lr_decay_iters = 250 # == max_iters\n",
    "min_lr = 6e-5\n",
    "\n",
    "eval_iters = 20\n",
    "eval_interval = 10\n",
    "\n",
    "grad_clip = 1.0\n",
    "\n",
    "eval_only = False\n",
    "eval_interval=1\n",
    "step = 0\n",
    "\n",
    "always_save_checkpoint = True\n",
    "restore = False\n",
    "\n",
    "seed = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0666b4cf-de36-46eb-b843-ba07a0dd9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = dict(n_layer=n_layer, \n",
    "                  n_head=n_head, \n",
    "                  n_embd=n_embd,\n",
    "                  block_size=block_size,\n",
    "                  bias=bias,\n",
    "                  vocab_size=vocab_size,\n",
    "                  dropout=dropout,\n",
    "                  seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a18b3ce-bc94-444c-b924-1b07dae0d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layer': 8,\n",
       " 'n_head': 8,\n",
       " 'n_embd': 32,\n",
       " 'block_size': 32,\n",
       " 'bias': True,\n",
       " 'vocab_size': 39,\n",
       " 'dropout': 0.1,\n",
       " 'seed': 1337}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9372625b-c92b-475f-a173-53809b19a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_directory = \"./checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47be03d4-4920-42b0-a7fe-1b3999d344f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e3a3dbc-1415-42eb-9294-fb282694bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f615795-1638-4d16-80bd-0690d6e04c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_config):\n",
    "    return GPT(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c7e7795-3aff-4296-b31e-6b411b87b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptconf = GPTConfig(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c634ad57-ee4c-4757-8ec6-cbb3e9ecac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_dist = strategy.experimental_distribute_dataset(train_set)\n",
    "valid_set_dist = strategy.experimental_distribute_dataset(valid_set.take(eval_iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c235d-c04a-4756-9c25-4a0a656c17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True,\n",
    "        reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    def compute_loss(Y, logits, model_losses):\n",
    "        per_example_loss = loss_object(tf.reshape(Y, [-1]),\n",
    "                      tf.reshape(logits, [-1, logits.shape[-1]]))\n",
    "        loss = tf.nn.compute_average_loss(per_example_loss)\n",
    "        if model_losses:\n",
    "            loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
    "        return loss\n",
    "\n",
    "    val_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name='train_accuracy')\n",
    "    val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name='val_accuracy')\n",
    "\n",
    "    model = build_model(gptconf)\n",
    "\n",
    "    tb_callback.set_model(model)\n",
    "\n",
    "    callbacks = tf.keras.callbacks.CallbackList([\n",
    "        tb_callback\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.AdamW(learning_rate=MyLRSchedule(learning_rate, warmup_iters, min_lr, lr_decay_iters))\n",
    "    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "    \n",
    "    ckpt = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                               optimizer=optimizer,\n",
    "                               model=model,\n",
    "                               model_args=model_args,\n",
    "                               best_val_loss=tf.Variable(best_val_loss),\n",
    "                               train_accuracy=train_accuracy,\n",
    "                               val_accuracy=val_accuracy,\n",
    "                               val_loss=val_loss)\n",
    "\n",
    "    manager = tf.train.CheckpointManager(ckpt, checkpoint_directory, max_to_keep=3)\n",
    "\n",
    "    if restore:\n",
    "        ckpt.restore(manager.latest_checkpoint)\n",
    "        #ckpt.restore(manager.checkpoints[-2])\n",
    "        step = int(ckpt.step.value().numpy())\n",
    "        best_val_loss = float(ckpt.best_val_loss.value().numpy())\n",
    "        model = ckpt.model\n",
    "        optimizer = ckpt.optimizer\n",
    "        model_args=ckpt.model_args\n",
    "        train_accuracy=ckpt.train_accuracy\n",
    "        val_accuracy=ckpt.val_accuracy\n",
    "        val_loss=ckpt.val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e26398d0-f97f-48c6-b6d0-4844eeaad35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(sample):\n",
    "    X, Y = sample\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(X, training=True)\n",
    "        loss = compute_loss(Y, logits, model.losses)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss)\n",
    "    \n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    gradients = [tf.clip_by_value(gradient,\n",
    "                                  clip_value_min=-grad_clip,\n",
    "                                  clip_value_max=grad_clip) for gradient in gradients]\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_accuracy.update_state(tf.reshape(Y, [-1]),\n",
    "                      tf.reshape(logits, [-1, logits.shape[-1]]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e86edda2-3161-4ba6-b718-e0d4617807c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(sample):\n",
    "    X, Y = sample\n",
    "    logits = model(X, training=False)\n",
    "    v_loss = loss_object(tf.reshape(Y, [-1]),\n",
    "                      tf.reshape(logits, [-1, logits.shape[-1]]))\n",
    "    val_loss.update_state(v_loss)\n",
    "    val_accuracy(tf.reshape(Y, [-1]),\n",
    "                      tf.reshape(logits, [-1, logits.shape[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dedc450-8de8-42c8-b6d6-c30d2761dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributed_train_epoch(dataset, step):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for sample in dataset:\n",
    "        callbacks.on_train_batch_begin(step)\n",
    "        per_replica_losses = strategy.run(train_step, args=(sample,))\n",
    "        callbacks.on_train_batch_end(step)\n",
    "        total_loss += strategy.reduce(\n",
    "            tf.distribute.ReduceOp.SUM,\n",
    "            per_replica_losses,\n",
    "            axis=None)\n",
    "        num_batches += 1\n",
    "    return total_loss / float(num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a2617ea-3cca-48a8-83e7-81ba54d14ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributed_val_epoch(dataset, step):\n",
    "    for sample in dataset:\n",
    "        callbacks.on_test_batch_begin(step)\n",
    "        strategy.run(val_step, args=(sample,))\n",
    "        callbacks.on_test_batch_end(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5570f4d7-8b27-48e5-b9d6-afe06004c1b7",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "824704fe-608b-452b-a6a3-b9f091d56d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 22:06:04.169943: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:59] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. drop/dropout/random_uniform/RandomUniform\n",
      "2024-03-24 22:06:06.591090: I external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:326] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_102', 540 bytes spill stores, 540 bytes spill loads\n",
      "\n",
      "2024-03-24 22:06:06.604877: I external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:326] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_102', 540 bytes spill stores, 540 bytes spill loads\n",
      "\n",
      "2024-03-24 22:06:06.758257: I external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:326] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_102', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-03-24 22:06:10.067625: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator case/Assert/AssertGuard/Assert\n",
      "2024-03-24 22:06:53.140999: I external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:326] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_102', 540 bytes spill stores, 540 bytes spill loads\n",
      "\n",
      "2024-03-24 22:06:53.222782: I external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:326] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_102', 540 bytes spill stores, 540 bytes spill loads\n",
      "\n",
      "2024-03-24 22:06:53.440661: I external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:326] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_102', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 0\n",
      "Loss: 2.9391627311706543, Accuracy: 16.80999183654785\n",
      "Val Loss: 2.605363130569458, Val Accuracy: 25.329893112182617\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1\n",
      "Loss: 2.5511412620544434, Accuracy: 25.636356353759766\n",
      "Val Loss: 2.4743571281433105, Val Accuracy: 25.61859130859375\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 2\n",
      "Loss: 2.494607448577881, Accuracy: 25.62923812866211\n",
      "Val Loss: 2.4435832500457764, Val Accuracy: 25.584714889526367\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 3\n",
      "Loss: 2.4789509773254395, Accuracy: 25.709205627441406\n",
      "Val Loss: 2.4333133697509766, Val Accuracy: 25.70556640625\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 4\n",
      "Loss: 2.4720842838287354, Accuracy: 25.813186645507812\n",
      "Val Loss: 2.4282569885253906, Val Accuracy: 25.714111328125\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 5\n",
      "Loss: 2.468085289001465, Accuracy: 25.8889102935791\n",
      "Val Loss: 2.425224781036377, Val Accuracy: 25.809019088745117\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 6\n",
      "Loss: 2.465149402618408, Accuracy: 25.946197509765625\n",
      "Val Loss: 2.4232497215270996, Val Accuracy: 25.86212158203125\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 7\n",
      "Loss: 2.462794303894043, Accuracy: 26.002784729003906\n",
      "Val Loss: 2.421194314956665, Val Accuracy: 25.945741653442383\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 8\n",
      "Loss: 2.460670232772827, Accuracy: 26.041757583618164\n",
      "Val Loss: 2.419156074523926, Val Accuracy: 26.066286087036133\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 9\n",
      "Loss: 2.4588215351104736, Accuracy: 26.076990127563477\n",
      "Val Loss: 2.417896270751953, Val Accuracy: 26.077880859375\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 10\n",
      "Loss: 2.4571402072906494, Accuracy: 26.10372543334961\n",
      "Val Loss: 2.416059970855713, Val Accuracy: 26.13983154296875\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 11\n",
      "Loss: 2.455686569213867, Accuracy: 26.12723731994629\n",
      "Val Loss: 2.415555953979492, Val Accuracy: 26.10321044921875\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 12\n",
      "Loss: 2.4544589519500732, Accuracy: 26.15036392211914\n",
      "Val Loss: 2.413545608520508, Val Accuracy: 26.1895751953125\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 13\n",
      "Loss: 2.4534034729003906, Accuracy: 26.168283462524414\n",
      "Val Loss: 2.4128737449645996, Val Accuracy: 26.1993408203125\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 14\n",
      "Loss: 2.4524495601654053, Accuracy: 26.179948806762695\n",
      "Val Loss: 2.4124488830566406, Val Accuracy: 26.253049850463867\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 15\n",
      "Loss: 2.4516921043395996, Accuracy: 26.19065284729004\n",
      "Val Loss: 2.411752939224243, Val Accuracy: 26.24908447265625\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 16\n",
      "Loss: 2.4509341716766357, Accuracy: 26.197853088378906\n",
      "Val Loss: 2.4111735820770264, Val Accuracy: 26.21856689453125\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 17\n",
      "Loss: 2.450406789779663, Accuracy: 26.208463668823242\n",
      "Val Loss: 2.4103875160217285, Val Accuracy: 26.289670944213867\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 18\n",
      "Loss: 2.449902296066284, Accuracy: 26.21246337890625\n",
      "Val Loss: 2.410139560699463, Val Accuracy: 26.246339797973633\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "Epoch 19\n",
      "Loss: 2.4493186473846436, Accuracy: 26.21527862548828\n",
      "Val Loss: 2.409715175628662, Val Accuracy: 26.290283203125\n",
      "Saving checkpoint to ./checkpoints/ckpt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(step)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train Epoch            \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mdistributed_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Val Epoch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m distributed_val_epoch(valid_set_dist, step)\n",
      "Cell \u001b[0;32mIn[37], line 6\u001b[0m, in \u001b[0;36mdistributed_train_epoch\u001b[0;34m(dataset, step)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m      5\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m----> 6\u001b[0m     per_replica_losses \u001b[38;5;241m=\u001b[39m \u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step)\n\u001b[1;32m      8\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39mreduce(\n\u001b[1;32m      9\u001b[0m         tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mReduceOp\u001b[38;5;241m.\u001b[39mSUM,\n\u001b[1;32m     10\u001b[0m         per_replica_losses,\n\u001b[1;32m     11\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:700\u001b[0m, in \u001b[0;36mMirroredExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m--> 700\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmirrored_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_container_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:84\u001b[0m, in \u001b[0;36mcall_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     wrapped \u001b[38;5;241m=\u001b[39m fn\u001b[38;5;241m.\u001b[39m_clone(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     82\u001b[0m         python_function\u001b[38;5;241m=\u001b[39mwrapped_fn)\n\u001b[1;32m     83\u001b[0m     _cfer_fn_cache[strategy][fn] \u001b[38;5;241m=\u001b[39m wrapped\n\u001b[0;32m---> 84\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m     87\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog_first_n(\n\u001b[1;32m     88\u001b[0m       logging\u001b[38;5;241m.\u001b[39mWARN, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m eagerly has significant \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverhead currently. We will be working on improving \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` inside a tf.function to get \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe best performance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m strategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks.on_train_begin()\n",
    "\n",
    "while True:\n",
    "    callbacks.on_epoch_begin(step)\n",
    "    # Train Epoch            \n",
    "    train_loss = distributed_train_epoch(train_set_dist, step)\n",
    "    \n",
    "    # Val Epoch\n",
    "    distributed_val_epoch(valid_set_dist, step)\n",
    "    callbacks.on_epoch_end(step)\n",
    "    out_format = (\"Epoch {}\\nLoss: {}, Accuracy: {}\\nVal Loss: {}, Val Accuracy: {}\")\n",
    "    print(out_format.format(step, train_loss, train_accuracy.result() * 100, val_loss.result(), val_accuracy.result() * 100 ))\n",
    "\n",
    "    # Checkpointing\n",
    "    if step > 0:\n",
    "        if val_loss.result() < best_val_loss or always_save_checkpoint:\n",
    "            best_val_loss = val_loss.result()\n",
    "            print(f'Saving checkpoint to {checkpoint_prefix}')\n",
    "            ckpt.step.assign(step)\n",
    "            ckpt.best_val_loss.assign(best_val_loss)\n",
    "            manager.save()\n",
    "    \n",
    "    train_accuracy.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    \n",
    "    step += 1\n",
    "    if step > max_iters:\n",
    "        break\n",
    "        \n",
    "callbacks.on_train_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad0054-dfb6-449e-9453-8fce97bf2ee1",
   "metadata": {},
   "source": [
    "## Model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54edaf2d-4faa-438d-ab5d-6fa1cc2f25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "inference_model = GPT(gptconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b95fd56-854e-4d12-b4a6-4410f6e5dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_chkpt = tf.train.Checkpoint(model=inference_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea344315-1e62-41ef-bb48-2936f995ad09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x774b185b7640>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_chkpt.restore(manager.checkpoints[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be9b7e1-bcbc-48d9-b400-b426a4719f05",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "742753a9-b07e-4fec-b75a-30b1220be2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(gen_txt, text_vec_layer):\n",
    "    out = []\n",
    "    gen_txt = gen_txt + 2\n",
    "    reverse = text_vec_layer.get_vocabulary()\n",
    "    decoder = lambda x: str(reverse[x])\n",
    "    gen_shape = gen.shape\n",
    "    gen_flat = tf.reshape(gen_txt, -1)\n",
    "    res = tf.map_fn(decoder, gen_flat, fn_output_signature='string')\n",
    "    res = tf.reshape(res, gen_shape)\n",
    "    res = res.numpy()\n",
    "    for sentence in res:\n",
    "        out.append(b\"\".join(sentence).decode())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6195543-203f-4307-9472-bad6d7c8e749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespear_txt[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65a9bafd-3425-4113-8a7d-d6136eb1972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = tf.reshape(text_vec_layer(shakespear_txt[:32]), shape=(-1, 32)) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fe3379b-20c5-42fb-ba89-38e1608a375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = inference_model.generate(txt, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4692ebf-1b3f-4d07-9314-234a06b6e6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first citizen:\\nbefore we proceedddvvvvvvdddddddddddddddddddddddd']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(gen, text_vec_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e5b7c-893d-4dd0-b5b5-912a054c6f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80515007-f126-46b1-a37a-a61e417a5bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
