{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f2d32d-a2a5-4d07-82a8-a75f9d59a5c2",
   "metadata": {},
   "source": [
    "## Translating NanoGPT (GPT2) to TensorFlow\n",
    "\n",
    "#### Based on https://github.com/karpathy/nanoGPT/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd63294-aad8-43f0-af26-fd269065c3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 18:07:49.903543: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-19 18:07:49.928749: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-19 18:07:49.928768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-19 18:07:49.929459: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-19 18:07:49.933685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-19 18:07:50.381492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from  dataclasses import dataclass\n",
    "from tensorflow.experimental import numpy as tnp\n",
    "import tensorflow_probability as tfp\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e066ce-3b7f-4b67-9baf-0447689759ca",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1815235f-5c52-47f2-b907-d76302440ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayerNorm(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, bias=True, eps=1e-6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "        self.bias = bias\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        self.weight = self.add_weight(name='weight',\n",
    "                                      shape=input_shape[-1:], # [-1:] gives last elem but keeps dims\n",
    "                                      initializer=tf.keras.initializers.Ones(),\n",
    "                                      trainable=True)\n",
    "\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                      shape=input_shape[-1:], # [-1:] gives last elem but keeps dims\n",
    "                                      initializer=tf.keras.initializers.Zeros(),\n",
    "                                      trainable=True) if self.bias else None\n",
    "\n",
    "        super(MyLayerNorm, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        # Can also use tf.nn.moments(inputs, axes=-1, keepdims=True), \n",
    "        # but then additionally one needs to take the sqrt to get \\sigma\n",
    "        mean = tf.keras.backend.mean(x, axis=-1, keepdims=True)\n",
    "        std = tf.keras.backend.std(x, axis=-1, keepdims=True)\n",
    "        \n",
    "        return self.weight * (x - mean) / (std + self.eps) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30015f0-edcb-4f58-95ba-7ef0b1f9b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 8 # 1024 for GPT2\n",
    "    vocab_size: int = 20 # 50304 for GPT2\n",
    "    n_layer: int = 2 # 12\n",
    "    n_head: int = 2 # 12\n",
    "    n_embd: int = 10 # 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "    seed: int = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62748a28-fe5e-447a-9ee0-364f628721b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0, \"Embedding dimension must divide number of heads\"\n",
    "        # key, query, value computed at once and splitted later\n",
    "        self.initializer_proj = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02 / tf.math.sqrt(2. * config.n_layer), seed=None)\n",
    "        self.c_attn = tf.keras.layers.Dense(#config.n_embd,\n",
    "                                            3 * config.n_embd,\n",
    "                                            activation=None,\n",
    "                                            use_bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = tf.keras.layers.Dense(#config.n_embd,\n",
    "                                            config.n_embd,\n",
    "                                            activation=None,\n",
    "                                            kernel_initializer=self.initializer_proj,\n",
    "                                            use_bias=config.bias)\n",
    "        self.dropout = config.dropout\n",
    "        self.attn_dropout = tf.keras.layers.Dropout(self.dropout)\n",
    "        self.resid_dropout = tf.keras.layers.Dropout(self.dropout)\n",
    "\n",
    "        self.mask = tf.experimental.numpy.tril(\n",
    "            tf.ones([config.block_size, config.block_size]))[tf.newaxis, tf.newaxis, :, :]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, C = x.size() # batch, sequence and channel, which is the embedding dim\n",
    "\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, axis=2)\n",
    "        k = tf.transpose(tf.reshape(k, [B, T, self.n_head, C // self.n_head]),\n",
    "                         perm=[0, 2, 1, 3])\n",
    "        q = tf.transpose(tf.reshape(q, [B, T, self.n_head, C // self.n_head]),\n",
    "                         perm=[0, 2, 1, 3])\n",
    "        v = tf.transpose(tf.reshape(v, [B, T, self.n_head, C // self.n_head]),\n",
    "                         perm=[0, 2, 1, 3])\n",
    "\n",
    "        att = (q @ tf.transpose(k, perm=[0, 1, 3, 2])) * (1.0 / tf.math.sqrt(k.shape[-1]))\n",
    "\n",
    "        mask = tf.experimental.numpy.tril(tf.ones([T, T]))[tf.newaxis, tf.newaxis, :, :]\n",
    "        att = tf.where(mask != 0, att, tf.constant(-np.inf))\n",
    "        att = tf.nn.softmax(att, axis = 3)\n",
    "        att = self.attn_dropout(att)\n",
    "        y = att @ v\n",
    "\n",
    "        y = tf.reshape(tf.transpose(y, perm=[0, 2, 1, 3]), [B, T, C])\n",
    "\n",
    "        return self.resid_dropout(self.c_proj(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f03ff7b-782a-44ce-90d6-740bea8696d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.initializer_proj = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02 / tf.math.sqrt(2. * config.n_layer), seed=None)\n",
    "        # Streching and shrinking in channel/embedding dimension,\n",
    "        # like for large resnets\n",
    "        self.c_fc = tf.keras.layers.Dense(4 * config.n_embd, activation=None, use_bias=config.bias)\n",
    "        self.c_proj = tf.keras.layers.Dense(config.n_embd, activation=None, kernel_initializer=self.initializer_proj, use_bias=config.bias)\n",
    "        self.gelu = tf.keras.activations.gelu\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return self.dropout(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b9f2e7-a6ca-42f1-a4f1-9fd4c70a5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = MyLayerNorm(bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = MyLayerNorm(bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        return x + self.mlp(self.ln_2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c27098-de9a-4d27-81dd-03252d470f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(tf.keras.models.Model):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "\n",
    "        self.initializer_dense = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02, seed=self.config.seed)\n",
    "        self.initializer_embed = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02, seed=self.config.seed)\n",
    "        self.initializer_bias = tf.keras.initializers.Zeros()\n",
    "        \n",
    "        self.wte = tf.keras.layers.Embedding(self.config.vocab_size, self.config.n_embd, \n",
    "                                             embeddings_initializer=self.initializer_embed, name='wte')\n",
    "        self.wpe = tf.keras.layers.Embedding(self.config.block_size, self.config.n_embd, \n",
    "                                             embeddings_initializer=self.initializer_embed, name='wpe')\n",
    "        self.drop = tf.keras.layers.Dropout(self.config.dropout, name='drop')\n",
    "        self.h = [Block(self.config) for _ in range(self.config.n_layer)]\n",
    "        self.ln_f = MyLayerNorm(bias=self.config.bias, name='ln_f')\n",
    "\n",
    "        self.lm_head = tf.keras.layers.Dense(self.config.vocab_size, use_bias=self.config.bias)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.wte.build(input_shape=[self.config.vocab_size])\n",
    "        self.lm_head.build(input_shape=[self.config.n_embd])\n",
    "        self.wte.trainable_weights[0].assign(tf.transpose(self.lm_head.trainable_weights[0]))\n",
    "        \n",
    "    def call(self, idx, targets=None):\n",
    "        b, t = idx.shape\n",
    "        assert t <= self.config.block_size, f'sequence too long for the defined context of {self.config.block_size}'\n",
    "        pos = tf.range(0, t, dtype=tf.int64)\n",
    "\n",
    "        tok_emb = self.wte(idx)\n",
    "        pos_emb = self.wpe(pos)\n",
    "        x = self.drop(tok_emb + pos_emb)\n",
    "        for block in self.h:\n",
    "            x = block(x)\n",
    "        x = self.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "            logits = self.lm_head(x)\n",
    "            \n",
    "            #print(tf.reshape(targets, [-1]).shape)\n",
    "            #print(tf.reshape(logits, [-1, logits.shape[-1]]).shape)\n",
    "            \n",
    "            loss = ce(tf.reshape(targets, [-1]),\n",
    "                      tf.reshape(logits, [-1, logits.shape[-1]]))\n",
    "        else:\n",
    "            logits = self.lm_head(x[:, -1, :])[:, tf.newaxis, :]\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def crop_block_size(self, block_size):\n",
    "        assert block_size < self.config.block_size\n",
    "        self.config.block_size = block_size\n",
    "        self.wpe.weights[0] = tf.Variable(self.wpe.weights[0][:block_size], trainable=True)\n",
    "        for block in self.h:\n",
    "            if hasattr(block.attn, 'bias'):\n",
    "                block.attn.bias = block.attn.bias[:, :, :block_size, :block_size]\n",
    "        \n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        n_params = self.count_params()\n",
    "        if non_embedding:\n",
    "            n_params -= self.wpe.count_params()\n",
    "        return n_params\n",
    "    \n",
    "    def estimate_mfu(self, fwdbwd_per_iter, dt):\n",
    "        N = self.get_num_params()\n",
    "        L, H, Q, T = self.config.n_layer, self.config.n_head, self.config.n_embd / self.config.n_head, self.config.block_size\n",
    "        flops_per_token = 6 * N + 12 * L * H * Q * T\n",
    "        flops_per_fwdbwd = flops_per_token * T\n",
    "        flops_per_iter = flops_per_fwdbwd * fwdbwd_per_iter\n",
    "        flops_achieved = flops_per_iter * (1.0/dt)\n",
    "        flops_promised = 312e12 # A100 at bfloat16\n",
    "        mfu = flops_achieved / flops_promised\n",
    "        return mfu\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        for i in range(max_new_tokens):\n",
    "            idx_cond = idx if idx.shape[1] <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, _ = tf.math.top_k(logits, min(top_k, logits.shape[-1]))\n",
    "                # Returned top_k values are sorted, so [-1] is the smallest of top_k\n",
    "                # and we cut all below that value\n",
    "                logits[logits < v[:, -1]] = -float('Inf')\n",
    "            probs = tf.keras.activations.softmax(logits, axis=-1)\n",
    "            idx_dist = tfp.distributions.Multinomial(total_count=1, probs=probs)\n",
    "            idx_next = idx_dist.sample(1)\n",
    "            idx_next = tf.reshape(tf.math.argmax(idx_next, axis=-1), shape=(-1, 1))\n",
    "            idx = tf.concat([idx, idx_next], axis=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "918718bb-997f-4470-8cfe-bd17a1539eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = GPTConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "de4b91fa-8fdd-4472-b930-2be16cc4370c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTConfig(block_size=8, vocab_size=20, n_layer=2, n_head=2, n_embd=10, dropout=0.0, bias=True, seed=1337)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "53bab698-a256-4958-a02f-97e9af6e3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = tf.constant(np.random.randint(0, 9, size=[2, 8]), dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "081ea851-b392-418b-9920-7a193dc32757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
       "array([[3, 1, 8, 3, 0, 3, 6, 8],\n",
       "       [2, 7, 0, 7, 6, 5, 8, 2]])>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "06239357-d63e-4851-b9fd-f6709f73690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fc303292-68b9-4094-8cd8-352bb0b0ca33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 8, 20), dtype=float32, numpy=\n",
       " array([[[ 0.4274856 , -0.06014805,  1.8340145 ,  2.919419  ,\n",
       "           0.44632468,  0.31492844,  0.6288445 , -1.4740782 ,\n",
       "           0.18079159, -0.26295385, -0.5100614 , -0.05964876,\n",
       "          -0.48101842, -1.2206202 , -0.51501125, -0.0133401 ,\n",
       "          -0.11798257, -0.46437418,  0.9749199 , -0.73925036],\n",
       "         [ 0.02297247,  2.6380482 ,  0.16860771, -0.00409502,\n",
       "           1.4361117 ,  0.6396625 ,  0.1880045 ,  0.7027596 ,\n",
       "          -0.12826179,  0.6724812 , -1.3839304 ,  0.05561219,\n",
       "           1.4390004 , -0.08324537, -0.39451855,  0.41270292,\n",
       "           1.794532  ,  0.42497164, -0.21578485,  1.0269561 ],\n",
       "         [ 0.42997706, -0.1618574 ,  0.39848232,  0.39548135,\n",
       "           0.1931145 ,  0.21241042, -0.05936687, -0.7839963 ,\n",
       "           2.0015707 , -0.17732549, -0.28062558,  0.29340756,\n",
       "          -0.6812506 , -0.94440085,  0.8995163 , -1.3410667 ,\n",
       "          -0.16206568,  0.49769974, -0.7805122 , -0.2991427 ],\n",
       "         [ 0.44027796, -0.03563954,  1.8611115 ,  2.918157  ,\n",
       "           0.4875484 ,  0.36393893,  0.67396784, -1.5018653 ,\n",
       "           0.24394247, -0.22710907, -0.5447492 , -0.10886243,\n",
       "          -0.49926877, -1.2556354 , -0.4496538 ,  0.01027814,\n",
       "          -0.03563245, -0.3974866 ,  1.0165888 , -0.7735279 ],\n",
       "         [ 2.1414297 ,  0.05312123, -1.1412265 ,  0.6651482 ,\n",
       "           0.05290971, -0.8236295 ,  1.4646019 , -1.016973  ,\n",
       "           0.38051257, -0.17866826, -0.9056155 , -0.6170363 ,\n",
       "          -1.0789915 , -0.81568944,  0.43348384,  1.3381827 ,\n",
       "          -0.21562578, -1.2018353 , -0.34808323, -0.93169177],\n",
       "         [ 0.46931562, -0.05365486,  1.8250543 ,  2.9183052 ,\n",
       "           0.40665248,  0.33528733,  0.6080033 , -1.5316172 ,\n",
       "           0.2853558 , -0.22042173, -0.49539524, -0.06715237,\n",
       "          -0.5368481 , -1.2965971 , -0.40174383, -0.09349903,\n",
       "          -0.07463118, -0.42808795,  0.97704333, -0.81843805],\n",
       "         [ 1.1329846 ,  0.20347968, -0.2696407 ,  0.7751526 ,\n",
       "           0.6596883 ,  0.09683734,  2.4658608 , -0.6993578 ,\n",
       "          -0.20714596, -1.2990298 , -1.5043732 , -1.8885213 ,\n",
       "          -0.6455579 , -0.9976143 , -0.69583833,  2.2805622 ,\n",
       "           0.3177327 , -0.53604907,  0.14731452, -0.25439277],\n",
       "         [ 0.42335424, -0.16385171,  0.43106425,  0.40747693,\n",
       "           0.25306892,  0.1699239 , -0.15076277, -0.7846906 ,\n",
       "           2.008937  , -0.02597304, -0.2565127 ,  0.40619874,\n",
       "          -0.5957509 , -0.8829445 ,  0.97245806, -1.3662435 ,\n",
       "          -0.13901037,  0.5022015 , -0.72520274, -0.37258726]],\n",
       " \n",
       "        [[-0.97128105,  0.14667308,  2.7177038 ,  1.9873545 ,\n",
       "           0.5978401 ,  1.3281358 , -0.28368503, -0.05650033,\n",
       "           0.18583041,  0.4585275 ,  0.29974073,  0.18753777,\n",
       "           0.3068169 , -0.22458498, -0.18980879, -0.5605715 ,\n",
       "           0.87715316,  1.139421  ,  1.5621686 , -0.10213561],\n",
       "         [-0.8441631 ,  0.6924161 , -0.08088496, -1.677344  ,\n",
       "          -0.12720098,  0.7531762 , -0.6647686 ,  2.540261  ,\n",
       "          -0.6274807 ,  0.5976709 ,  0.8620621 , -0.03193472,\n",
       "           1.1046735 ,  1.4493785 ,  0.14520814,  0.33108535,\n",
       "           1.2737322 ,  1.2676752 ,  0.19469056,  0.8271639 ],\n",
       "         [ 2.136324  , -0.06344803, -1.1342384 ,  0.70560807,\n",
       "          -0.08736416, -0.7868713 ,  1.5234525 , -1.1065063 ,\n",
       "           0.4526741 , -0.39146   , -0.87313235, -0.7267242 ,\n",
       "          -1.245757  , -0.9584455 ,  0.39553434,  1.243835  ,\n",
       "          -0.32681137, -1.2113807 , -0.4146116 , -0.93476176],\n",
       "         [-0.9206353 ,  0.72270334,  0.06139433, -1.6357415 ,\n",
       "          -0.06042978,  0.8799873 , -0.6267076 ,  2.5394278 ,\n",
       "          -0.57317775,  0.6112908 ,  0.8381661 , -0.09762476,\n",
       "           1.1142485 ,  1.4172473 ,  0.16688019,  0.33162895,\n",
       "           1.3914782 ,  1.4068255 ,  0.28691912,  0.83587766],\n",
       "         [ 1.176485  ,  0.2696536 , -0.2312566 ,  0.7917884 ,\n",
       "           0.6537454 ,  0.16735978,  2.4698403 , -0.6265867 ,\n",
       "          -0.19423541, -1.190162  , -1.4618131 , -1.8880808 ,\n",
       "          -0.68860614, -0.94779176, -0.62220365,  2.3148246 ,\n",
       "           0.4340716 , -0.45900732,  0.22242002, -0.23715332],\n",
       "         [-0.9203967 ,  0.884836  ,  1.9544291 ,  0.6211535 ,\n",
       "           0.24573222,  1.9654088 ,  0.11723168,  0.9322117 ,\n",
       "           0.22090016,  0.39204428,  0.31278226, -0.8278698 ,\n",
       "           0.2829195 , -0.20890889,  0.2571569 , -0.05249766,\n",
       "           2.0577362 ,  1.9205122 ,  1.4546535 ,  0.1637036 ],\n",
       "         [ 0.37361595, -0.13878864,  0.34830165,  0.3137189 ,\n",
       "           0.32339805,  0.06585483, -0.24425831, -0.79259664,\n",
       "           2.004016  , -0.02334581, -0.31348458,  0.5207156 ,\n",
       "          -0.45497712, -0.84986556,  0.92896247, -1.4407368 ,\n",
       "          -0.2226536 ,  0.43307558, -0.85253954, -0.33441195],\n",
       "         [-0.95961154,  0.17129599,  2.7198799 ,  1.9770492 ,\n",
       "           0.5600278 ,  1.381297  , -0.25170892, -0.06107962,\n",
       "           0.22865057,  0.43012202,  0.29605106,  0.10061973,\n",
       "           0.28879017, -0.3095103 , -0.14320585, -0.56866807,\n",
       "           0.9531497 ,  1.1850265 ,  1.5808284 , -0.16377187]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2271694>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt(txt, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a3cb3006-1a05-47cb-8bc5-196db4b33638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 8]\n",
      " [17]], shape=(2, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[6]\n",
      " [2]], shape=(2, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[15]\n",
      " [ 3]], shape=(2, 1), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 11), dtype=int64, numpy=\n",
       "array([[ 3,  1,  8,  3,  0,  3,  6,  8,  8,  6, 15],\n",
       "       [ 2,  7,  0,  7,  6,  5,  8,  2, 17,  2,  3]])>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.generate(txt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6660b840-4f2f-48a3-9610-9c12819bc82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " wte (Embedding)             multiple                  200       \n",
      "                                                                 \n",
      " wpe (Embedding)             multiple                  80        \n",
      "                                                                 \n",
      " drop (Dropout)              multiple                  0         \n",
      "                                                                 \n",
      " block_36 (Block)            multiple                  0         \n",
      "                                                                 \n",
      " block_37 (Block)            multiple                  0         \n",
      "                                                                 \n",
      " ln_f (MyLayerNorm)          multiple                  20        \n",
      "                                                                 \n",
      " dense_170 (Dense)           multiple                  220       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520 (2.03 KB)\n",
      "Trainable params: 520 (2.03 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b6c1d2cf-61ec-4ee7-95ec-9a9040bd7c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.wpe.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "41ddf176-7a27-421c-9b7f-9d43e9c80872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d2f006f2-4422-4566-954a-f03ac4245fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3384615384615383e-10"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.estimate_mfu(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6b6aa88c-e42d-4dce-a294-ae935a13cf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.config.block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b1359964-c033-497e-821c-c09280fba0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.crop_block_size(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3f642220-5223-46d1-ba2e-d372895c1266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTConfig(block_size=4, vocab_size=20, n_layer=2, n_head=2, n_embd=10, dropout=0.0, bias=True, seed=1337)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "27e843de-c566-4507-82a6-174a17315190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 1, 20), dtype=float32, numpy=\n",
       " array([[[ 0.44027796, -0.03563954,  1.8611115 ,  2.918157  ,\n",
       "           0.4875484 ,  0.36393893,  0.67396784, -1.5018653 ,\n",
       "           0.24394247, -0.22710907, -0.5447492 , -0.10886243,\n",
       "          -0.49926877, -1.2556354 , -0.4496538 ,  0.01027814,\n",
       "          -0.03563245, -0.3974866 ,  1.0165888 , -0.7735279 ]],\n",
       " \n",
       "        [[-0.9206353 ,  0.72270334,  0.06139433, -1.6357415 ,\n",
       "          -0.06042978,  0.8799873 , -0.6267076 ,  2.5394278 ,\n",
       "          -0.57317775,  0.6112908 ,  0.8381661 , -0.09762476,\n",
       "           1.1142485 ,  1.4172473 ,  0.16688019,  0.33162895,\n",
       "           1.3914782 ,  1.4068255 ,  0.28691912,  0.83587766]]],\n",
       "       dtype=float32)>,\n",
       " None)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt(txt[:, :4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b90f6-c158-4bce-bfa5-aeea6c0bae30",
   "metadata": {},
   "source": [
    "## Auxilliary routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f3b353c-e1a0-4d2e-8baa-5dcf1da99608",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    learning_rate: tf.float32 = learning_rate\n",
    "    warmup_iters: int = warmup_iters\n",
    "    min_lr: tf.float32 = min_lr \n",
    "    lr_decay_iters: int= lr_decay_iters\n",
    "    \n",
    "    def __call__(self, step):\n",
    "      if step < self.warmup_iters:\n",
    "          return self.learning_rate * float(step) / self.warmup_iters\n",
    "      if step > self.lr_decay_iters:\n",
    "          return self.min_lr\n",
    "      decay_ratio = (float(step) - self.warmup_iters) / (self.lr_decay_iters - self.warmup_iters)\n",
    "      assert 0 <= decay_ratio <= 1\n",
    "      coeff = 0.5 * (1.0 + tf.math.cos(tnp.pi * decay_ratio))\n",
    "      return self.min_lr + coeff * tf.cast((self.learning_rate - self.min_lr), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7452c0-ee4a-4828-9ffe-9bdbe9beca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss():\n",
    "    out = {'train': None, 'val': None}\n",
    "    \n",
    "    losses = tf.zeros(eval_iters)\n",
    "    k = tf.Variable(0, trainable=False)\n",
    "    for X, Y in train_set.take(eval_iters):\n",
    "        logits, loss = model(X, Y, training=False)\n",
    "        tf.tensor_scatter_nd_update(losses, [[k]], [loss])\n",
    "        k.assign_add(1)\n",
    "    out['train'] = tf.reduce_mean(loss)\n",
    "\n",
    "    losses = tf.zeros(eval_iters)\n",
    "    k = tf.Variable(0, trainable=False)\n",
    "    for X, Y in valid_set.take(eval_iters):\n",
    "        logits, loss = model(X, Y, training=False)\n",
    "        tf.tensor_scatter_nd_update(losses, [[k]], [loss])\n",
    "        k.assign_add(1)\n",
    "    out['val'] = tf.reduce_mean(loss)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38dbe2-be59-42cc-80cf-6acddd5b9a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593bc9f-6127-44bf-94ec-a228555812b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5445c587-127f-4847-a376-83137d4872eb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9783bf-ffd8-47a7-a96d-7e565b2fd426",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespear_url = \"https://homl.info/shakespeare\"\n",
    "filepath = tf.keras.utils.get_file('shakespear.txt', shakespear_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b924d61-10ce-4a53-9bcf-988ac292bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath, 'r', encoding='utf-8') as f:\n",
    "    shakespear_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc58f79-1e89-4670-968d-b5ac2ddeaf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(shakespear_txt[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "895d2e3f-a3b9-4206-8a42-9c8ef6878241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 18:07:57.173868: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 18:07:57.202271: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 18:07:57.202425: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 18:07:57.204811: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 18:07:57.204924: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 18:07:57.204997: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 18:07:57.245731: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 18:07:57.245839: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 18:07:57.245918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-19 18:07:57.245987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3902 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(split='character',\n",
    "                                                  standardize='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69510b33-0bc0-4949-8354-a3e46e6ce141",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer.adapt([shakespear_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cb9ef03-8cb6-460e-86e1-0f4ef25bddc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', ' ', 'e', 't', 'o', 'a', 'i', 'h', 's']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c1790fb-ae48-4d91-8271-52dd1e9728e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = text_vec_layer([shakespear_txt])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a193190e-994c-4102-9641-9b6094057233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48b4bc16-834b-4dcb-bf3a-9dcf99a75cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing code 0 and 1 reserved for padding and unknown characters \n",
    "# (codes start at 2 before that removal so now 0 and 1 will be some chars)\n",
    "encoded -= 2\n",
    "\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2\n",
    "dataset_size = len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f67da86c-ac61-4c4e-9a1d-df7ae567eed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ef9654-7a8f-46a7-bd8a-2c05f4c7eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42db9390-638c-4bc8-89a9-2fb3a8bf608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length+1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53836358-b36f-4325-ad67-69dfa6bd38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 8\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b70c83e-72b1-4449-87b5-c805e996e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = to_dataset(encoded[:1_060_000], length=length, shuffle=True, seed=1337)\n",
    "valid_set = to_dataset(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c389baff-d9d6-4592-8faa-1429d90f4320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 3 14  1 26 10 10 25  5]], shape=(1, 8), dtype=int64)\n",
      "tf.Tensor([[14  1 26 10 10 25  5  8]], shape=(1, 8), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for sample in train_set.rebatch(1).take(1):\n",
    "    print(sample[0])\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97a7a825-e4ca-4684-9fef-d50ebc0a500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 2\n",
    "n_head = 2 \n",
    "n_embd = 32\n",
    "block_size = length\n",
    "bias = True\n",
    "vocab_size = n_tokens\n",
    "dropout = tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "iter_num = 0\n",
    "best_val_loss = 1e9\n",
    "max_iters = 100\n",
    "\n",
    "init_from = 'scratch'\n",
    "\n",
    "weight_decay = tf.constant(1e-1, dtype=tf.float32)\n",
    "\n",
    "warmup_iters = 10\n",
    "learning_rate = tf.constant(6e-4, dtype=tf.float32)\n",
    "lr_decay_iters = 100 # == max_iters\n",
    "min_lr = tf.constant(6e-5, dtype=tf.float32)\n",
    "\n",
    "eval_iters = 20\n",
    "eval_interval = 10\n",
    "\n",
    "grad_clip = tf.constant(1.0, dtype=tf.float32)\n",
    "\n",
    "eval_only = False\n",
    "eval_interval=1\n",
    "step = 0\n",
    "\n",
    "always_save_checkpoint = True\n",
    "restore = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0666b4cf-de36-46eb-b843-ba07a0dd9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = dict(n_layer=n_layer, \n",
    "                  n_head=n_head, \n",
    "                  n_embd=n_embd,\n",
    "                  block_size=block_size,\n",
    "                  bias=bias,\n",
    "                  vocab_size=vocab_size,\n",
    "                  dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a18b3ce-bc94-444c-b924-1b07dae0d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layer': 2,\n",
       " 'n_head': 2,\n",
       " 'n_embd': 32,\n",
       " 'block_size': 8,\n",
       " 'bias': True,\n",
       " 'vocab_size': 39,\n",
       " 'dropout': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372625b-c92b-475f-a173-53809b19a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_directory = \"./checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a3b2d39-fdbc-4b83-8110-100c6c8e4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptconf = GPTConfig(**model_args)\n",
    "model = GPT(gptconf)\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=MyLRSchedule(learning_rate, warmup_iters, min_lr, lr_decay_iters))\n",
    "\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                           optimizer=optimizer, \n",
    "                           model=model,\n",
    "                           model_args=model_args,\n",
    "                           best_val_loss=tf.Variable(best_val_loss))\n",
    "                           #config=GPTConfig)\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, checkpoint_directory, max_to_keep=3)\n",
    "\n",
    "if restore:\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    step = int(ckpt.step)\n",
    "    best_val_loss = float(ckpt.best_val_loss)\n",
    "    model = ckpt.model\n",
    "    optimizer = ckpt.optimizer\n",
    "    model_args=ckpt.model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "49a20d00-713b-43cb-8eed-9254b62a960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, _ in train_set.take(1):\n",
    "    out = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c30241ec-6df0-4cc0-97f0-855235849fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 1, 39), dtype=float32, numpy=\n",
       " array([[[ 5.4931684e+00,  3.7205371e-01,  6.9388658e-01, ...,\n",
       "           1.4949246e-01,  2.6834235e-03,  7.0552784e-01]],\n",
       " \n",
       "        [[ 4.1647804e-01,  4.7048670e-01, -6.5505439e-01, ...,\n",
       "          -8.7842530e-01, -6.4945616e-02,  4.7188056e-01]],\n",
       " \n",
       "        [[ 5.4931684e+00,  3.7205371e-01,  6.9388658e-01, ...,\n",
       "           1.4949246e-01,  2.6834235e-03,  7.0552784e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4.1647804e-01,  4.7048670e-01, -6.5505439e-01, ...,\n",
       "          -8.7842530e-01, -6.4945616e-02,  4.7188056e-01]],\n",
       " \n",
       "        [[ 4.1647804e-01,  4.7048670e-01, -6.5505439e-01, ...,\n",
       "          -8.7842530e-01, -6.4945616e-02,  4.7188056e-01]],\n",
       " \n",
       "        [[ 5.4931684e+00,  3.7205371e-01,  6.9388658e-01, ...,\n",
       "           1.4949246e-01,  2.6834235e-03,  7.0552784e-01]]], dtype=float32)>,\n",
       " None)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85bcc203-f181-4761-9215-3cbe90912eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7: train loss 4.6512, val loss 4.6152\n",
      "Saving checkpoint to ./checkpoints/ckpt\n",
      "step 8: train loss 4.7170, val loss 4.6048\n",
      "Saving checkpoint to ./checkpoints/ckpt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m         losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Checkpointing\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 6\u001b[0m, in \u001b[0;36mestimate_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m losses \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros(eval_iters)\n\u001b[1;32m      5\u001b[0m k \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;241m0\u001b[39m, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m train_set\u001b[38;5;241m.\u001b[39mtake(eval_iters):\n\u001b[1;32m      7\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m model(X, Y, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     tf\u001b[38;5;241m.\u001b[39mtensor_scatter_nd_update(losses, [[k]], [loss])\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf39/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3024\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3023\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3026\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3027\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    if step % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # Checkpointing\n",
    "    if losses['val'] < best_val_loss or always_save_checkpoint:\n",
    "        best_val_loss = losses['val']\n",
    "        if step > 0:\n",
    "            print(f'Saving checkpoint to {checkpoint_prefix}')\n",
    "            ckpt.step.assign_add(1)\n",
    "            ckpt.best_val_loss.assign(best_val_loss)\n",
    "            manager.save()\n",
    "           \n",
    "    if step == 0 and eval_only:\n",
    "        break\n",
    "\n",
    "    for X, Y in train_set.take(4):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits, main_loss = model(X, Y, training=True)\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        gradients = [tf.clip_by_value(g, \n",
    "                                      clip_value_min=-grad_clip, \n",
    "                                      clip_value_max=grad_clip) for g in gradients]\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))    \n",
    "    \n",
    "    step += 1\n",
    "    if step > 20:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "99438fba-537b-4338-b9d5-70926839084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[20]\n",
      " [18]], shape=(2, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[20]\n",
      " [18]], shape=(2, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[34]\n",
      " [18]], shape=(2, 1), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 11), dtype=int64, numpy=\n",
       "array([[ 3,  1,  8,  3,  0,  3,  6,  8, 20, 20, 34],\n",
       "       [ 2,  7,  0,  7,  6,  5,  8,  2, 18, 18, 18]])>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(txt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396c579-5465-4d81-a731-fff96f798aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
